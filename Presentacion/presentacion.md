# üéì Universidad del Istmo ‚Äî Facultad de Ingenier√≠a

## **Proyecto Final de An√°lisis de Datos**

### **Construcci√≥n y Visualizaci√≥n de Grafos de Colaboraci√≥n y An√°lisis de Incidentes**

### üß© Integrantes del equipo

* **Carlos Solares**

---

# üß© Parte 1 ‚Äî Extracci√≥n de Datos desde la API de TMDB

## üé¨ Introducci√≥n

El objetivo de esta primera fase fue **obtener informaci√≥n real del mundo cinematogr√°fico** desde la base de datos p√∫blica **The Movie Database (TMDB)**, utilizando su **API REST**.
Con estos datos, se construy√≥ un **grafo de colaboraci√≥n entre actores**, que m√°s adelante ser√≠a visualizado y analizado.

El enfoque fue dise√±ado para **automatizar completamente** la extracci√≥n y limpieza de los datos, evitando la intervenci√≥n manual.
El resultado es un conjunto de datos confiables que representan **qu√© actores han trabajado juntos** y **en qu√© pel√≠culas**.

---

## ‚öôÔ∏è Arquitectura General del Flujo

1. **Definici√≥n del actor principal y rango de a√±os.**
   Se selecciona un actor base (por defecto, **Keanu Reeves**) y un rango de a√±os de an√°lisis (1985‚Äì2023).

2. **Consulta de filmograf√≠a.**
   Se usa el endpoint `/person/{id}/movie_credits` de TMDB para obtener todas las pel√≠culas en las que ha participado el actor dentro del rango definido.

3. **Obtenci√≥n de elencos.**
   Por cada pel√≠cula encontrada, se consulta su elenco usando `/movie/{id}/credits`.

---

4. **Procesamiento paralelo.**
   Para mejorar la velocidad, las consultas se ejecutan en **m√∫ltiples hilos** (threads), controlados con un **sem√°foro** que limita las llamadas simult√°neas a la API.

5. **Construcci√≥n del grafo.**
   Con los datos obtenidos, se van creando **nodos (actores)** y **aristas (colaboraciones)**.

6. **Exportaci√≥n de resultados.**
   Los resultados se guardan en un archivo `.dot`, que luego puede convertirse en un grafo visual (SVG o PNG).

---

## üß† L√≥gica del Proceso

### 1. Inicializaci√≥n

El programa define el actor principal y el rango de a√±os a analizar:

```cpp
int mainActorId = 6384; // Keanu Reeves
int startYear = 1985, endYear = 2023;
```

Esto permite concentrar la b√∫squeda solo en el periodo relevante, evitando exceso de datos.

---

### 2. Obtenci√≥n de la filmograf√≠a

Se utiliza una funci√≥n auxiliar en `TMDBAPIUtils.cpp`:

```cpp
std::vector<MovieData> filmography = TMDBAPIUtils::getMoviesForActor(mainActorId, startYear, endYear);
```

üîç **Qu√© hace internamente:**

* Construye la URL `https://api.themoviedb.org/3/person/{id}/movie_credits?api_key=...`
* Realiza una petici√≥n HTTP GET usando la librer√≠a **cpr**.
* Parsea la respuesta JSON con **nlohmann/json**.
* Filtra las pel√≠culas por a√±o de lanzamiento.
* Devuelve un vector con informaci√≥n estructurada:
  *(ID, t√≠tulo, a√±o, fecha de estreno)*

---

### 3. Extracci√≥n del elenco por pel√≠cula

Cada pel√≠cula del paso anterior se procesa en paralelo:

```cpp
std::vector<ActorData> cast = TMDBAPIUtils::getMovieCast(movieId);
```

üîç **Qu√© hace internamente:**

* Llama al endpoint `/movie/{id}/credits`.
* Obtiene la lista de actores con sus nombres e IDs.
* Limita el n√∫mero de resultados para evitar ruido.
* Excluye actores repetidos o no relevantes.

---

### 4. Paralelismo y control de concurrencia

Cada consulta a la API se ejecuta en un hilo separado.
Para evitar sobrecargar la API, se usa un **sem√°foro** que restringe el n√∫mero de llamadas simult√°neas:

```cpp
const int MAX_CONCURRENT_CALLS = 5;
std::counting_semaphore<MAX_CONCURRENT_CALLS> apiSemaphore(MAX_CONCURRENT_CALLS);
```

üí° Este mecanismo garantiza eficiencia sin violar las pol√≠ticas de uso de la API.

Adem√°s, se usa un **mutex** para proteger la estructura del grafo:

```cpp
std::lock_guard<std::mutex> lock(graphMutex);
```

Esto evita que varios hilos modifiquen el grafo al mismo tiempo.

---

### 5. Construcci√≥n del grafo de colaboraci√≥n

Cada vez que se obtiene un elenco, se agregan los actores y las colaboraciones entre ellos:

```cpp
graph.addActor(actor.id, actor.name);
graph.addCollaboration(actor1.id, actor2.id, movieTitle, movieYear);
```

üîó **Regla clave:**
Solo se guarda **la pel√≠cula m√°s reciente** donde dos actores colaboraron, lo cual evita duplicados y prioriza relevancia actual.

---

### 6. Exportaci√≥n y visualizaci√≥n

Al finalizar la extracci√≥n, se exporta el grafo a formato DOT:

```cpp
graph.exportToDot("colaboraciones.dot");
system("dot -Tsvg colaboraciones.dot -o grafo.svg");
```

Esto genera dos archivos:

* **`colaboraciones.dot`** ‚Üí formato de texto para Graphviz.
* **`grafo.svg`** ‚Üí visualizaci√≥n final del grafo.

---

## üß© Ejemplo de Resultado (simplificado)

```Ejemplo
Keanu Reeves
 ‚îú‚îÄ‚îÄ Sandra Bullock  ‚Äî Speed (1994)
 ‚îú‚îÄ‚îÄ Laurence Fishburne ‚Äî The Matrix (1999)
 ‚îú‚îÄ‚îÄ Carrie-Anne Moss ‚Äî The Matrix (1999)
 ‚îî‚îÄ‚îÄ Ian McShane ‚Äî John Wick (2014)
```

Cada l√≠nea representa una **colaboraci√≥n entre actores**, y cada conexi√≥n est√° etiquetada con la pel√≠cula m√°s reciente donde trabajaron juntos.

---

## üí¨ Conclusi√≥n

En esta primera etapa se logr√≥:

* Automatizar la **extracci√≥n de datos reales** desde la API de TMDB.
* Implementar un flujo **eficiente y concurrente** en C++20.
* Crear una **base estructurada de relaciones** actor‚Äìactor.
* Preparar los datos para su **almacenamiento, an√°lisis y visualizaci√≥n posterior**.

El resultado es un dataset s√≥lido, listo para ser procesado en la siguiente fase de la presentaci√≥n: **almacenamiento y visualizaci√≥n**.

¬°vamos! Aqu√≠ tienes la **Parte 2** en **Markdown**: c√≥mo usamos **base de datos + visualizaci√≥n** para transformar los datos crudos en hallazgos claros y presentables.

---

# üìä Parte 2 ‚Äî Base de Datos y Visualizaci√≥n

## üéØ Objetivo

Tomar los CSV originales (incidents, details, outcomes), **normalizarlos y cargarlos** en una **base SQLite**, y a partir de ah√≠ **generar visualizaciones reproducibles** que respondan preguntas de negocio espec√≠ficas.

---

## üß± Arquitectura t√©cnica (resumen)

* **Motor de BD:** SQLite (ligero, portable, cero-deps de servidor).
* **Carga de datos:** C++ (multi-hilo) con transacciones y *bulk inserts*.
* **Consultas:** SQL con limpieza/normalizaci√≥n ‚Äúon the fly‚Äù.
* **Gr√°ficas:** *matplotlib* desde C++ v√≠a un *wrapper* (`third_party/matplotlibcpp.h`).
* **Contenedores:** Docker + Docker Compose para reproducibilidad (sin instalar dependencias locales).

```
CSV ‚Üí (DbLoader) ‚Üí SQLite ‚Üí (Analytics SQL) ‚Üí ResultSets ‚Üí (Chart) ‚Üí PNG
```

---

## üê≥ Ejecuci√≥n reproducible con Docker

**docker-compose.yml** (fragmento):

```yaml
services:
  analytics:
    build:
      context: .
      dockerfile: docker/Dockerfile
    image: incidents-analytics:latest
    container_name: incidents-analytics
    volumes:
      - ./data:/app/data:ro
      - ./outputs:/app/outputs/images
```

* Montamos `./data` como **solo lectura** (garantiza integridad de insumos).
* Exportamos **PNG** a `./outputs` para consumo inmediato en la presentaci√≥n.

---

**Comando √∫nico**:

```bash
docker compose up --build --force-recreate
```

> Resultado: se crea/actualiza la BD SQLite, se ejecutan las consultas y se generan las figuras en `outputs/`.

---

## üóÑÔ∏è Ingesta y modelo de datos

### Esquema m√≠nimo (SQLite)

* **incidents** (`report_id` PK, `category`, `date`)
* **details** (`report_id`, `subject`, `transport_mode`, `detection`)
* **outcomes** (`report_id`, `outcome`, `num_ppl_fined`, `fine`, `num_ppl_arrested`, `prison_time`, `prison_time_unit`)

Indices por `report_id` para *joins* r√°pidos.

---

### Carga robusta (C++)

* **Transacciones** por archivo (`BEGIN‚Ä¶COMMIT`) para *bulk insert*.
* **Detecci√≥n de tipos**: enteros, reales, o texto limpio (se remueven `\r\n\t` y *trailing spaces*).
* **CSV parser** tolerante a comillas y comas dentro de campos.
* **Concurrencia segura**: se carga cada tabla en **conexi√≥n separada** (evita ‚Äútransaction within a transaction‚Äù), con l√≠mite de paralelismo (sem√°foro).
* **PRAGMA** de performance: `WAL` + `synchronous=NORMAL`.

> Beneficio: **tiempos de carga** bajos y **consistencia** incluso con archivos grandes o con ruido.

---

## üîé Consultas anal√≠ticas (SQL + limpieza)

La clase `Analytics` aplica **normalizaci√≥n en la consulta**, p. ej.:

* **Fechas:** se eliminan `CR/LF/espacios` y se valida con `GLOB '[YYYY-MM-DD]'` antes de castear el a√±o.
* **Unidades de prisi√≥n ‚Üí d√≠as:** conversi√≥n a una escala √∫nica (a√±os‚Üí365, meses‚Üí30, semanas‚Üí7).
* **Claves textuales:** `LOWER(TRIM(...))` y filtros de frecuencia para evitar categor√≠as espurias.

Esto nos permite **evitar ETLs pesados**, manteniendo la l√≥gica de limpieza **cerca de las preguntas**.

---

## üñºÔ∏è Visualizaci√≥n program√°tica

`Chart` usa un *wrapper* m√≠nimo a *matplotlib*:

* **Backend sin GUI** (`Agg`) ‚Üí funciona en Docker *headless*.
* **Gr√°ficas determin√≠sticas** (misma salida entre m√°quinas).
* **Formato**: PNG de alta calidad listo para informes.

---

### üìå Resultados y lectura ejecutiva

### (a) Incidentes por a√±o (2018‚Äì2020)

<p align="center">
  <img src="../Tablas/outputs/a_incidents_2018_2020.png" alt="Incidentes 2018‚Äì2020" width="40%">
</p>

**Qu√© muestra:** Conteo anual y **% respecto al total hist√≥rico** (t√≠tulo).
**Lectura:** Crecimiento 2018‚Üí2020; el per√≠odo representa **‚âà31.4%** del total de incidentes registrados.

---

### (b) Top 3 de modo de transporte (detecci√≥n = *intelligence*)

<p align="center">
  <img src="../Tablas/outputs/b_top3_transport_intelligence.png" alt="Incidentes 2018‚Äì2020" width="40%">
</p>

**Qu√© muestra:** Entre incidentes detectados por **inteligencia**, ¬øqu√© *transport_mode* domina?
**Lectura:** **Terrestre/veh√≠culo** concentra por mucho el mayor volumen; **mar** y **aire** quedan rezagados.

---

### (c) M√©todos de detecci√≥n por **promedio** de arrestos

<p align="center">
  <img src="../Tablas/outputs/c_detection_avg_arrests.png" alt="Incidentes 2018‚Äì2020" width="40%">
</p>

**Qu√© muestra:** Ordena los m√©todos de detecci√≥n por **efectividad operativa** (promedio de arrestos por caso).
**Lectura:** **operation** e **investigation** lideran; **online** y **other** rinden menos.

---

### (d) Categor√≠as con **mayores sentencias** (en d√≠as)

<p align="center">
  <img src="../Tablas/outputs/c_detection_avg_arrests.png" alt="Incidentes 2018‚Äì2020" width="40%">
</p>

**Qu√© muestra:** Promedio de d√≠as de prisi√≥n por **categor√≠a** del incidente (normalizando a√±os/meses/semanas a d√≠as).
**Lectura:** **Smuggling/Illegal Trade** y **Poaching/Illegal Harvesting** reciben las penas m√°s severas.

---

### (e) Serie anual de **multas totales**

<p align="center">
  <img src="../Tablas/outputs/e_fine_totals_per_year.png" alt="Incidentes 2018‚Äì2020" width="40%">
</p>

**Qu√© muestra:** Evoluci√≥n de las multas agregadas por a√±o.
**Lectura:** Ciclos notorios con picos y ca√≠das; posible **efecto pandemia** alrededor de 2020 y reajustes posteriores.

---

## ‚úÖ Validaciones y diagn√≥stico

Modo opcional `--diagnostico`:

* Conteos por tabla, rango de a√±os, *top-5* de categor√≠as/claves, sumas de multas y arrestos.
* √ötil para **sanidad de datos** y **re-ejecuciones r√°pidas**.

```bash
docker compose run --rm analytics --diagnostico
```

---

## üì¶ Decisiones de dise√±o (por qu√© as√≠)

* **SQLite**: portabilidad y cero fricci√≥n en despliegue/nota acad√©mica.
* **Limpieza en SQL**: menos pasos ETL; consultas auto-contenidas y auditables.
* **C++ con paralelismo controlado**: carga r√°pida sin violar bloqueos; *timeouts* y conexiones separadas evitan condiciones de carrera.
* **Docker**: entornos equivalentes para profesor, estudiante y cualquiera que quiera probarlo.

---

## üß† Conclusi√≥n de la Parte 2

* Transformamos CSV ruidosos en una **BD confiable** con un **pipeline reproducible**.
* Las consultas responden **preguntas accionables** (tendencias, efectividad operativa, severidad penal).
* Las **gr√°ficas** est√°n listas para incluirse en reportes ejecutivos y toman **segundos** en regenerarse.

> Siguiente paso (Parte 3): **reducci√≥n de dimensionalidad** para descubrir patrones latentes no obvios con variables m√∫ltiples (ej. PCA / Isomap) y enriquecer la toma de decisiones.

---

# üß† Parte 3 ‚Äî Reducci√≥n de Dimensionalidad con ISOMAP

## üéØ Objetivo

Reducir un conjunto de **7129 variables g√©nicas** a **dos dimensiones** de manera que se conserven las **relaciones geom√©tricas reales** entre muestras biol√≥gicas (pacientes con leucemia).
El prop√≥sito es **visualizar patrones ocultos** que no son evidentes en el espacio original de alta dimensi√≥n.

---

## üß¨ Contexto del Dataset

* **Tipo de datos:** Expresi√≥n g√©nica (niveles de activaci√≥n de genes)
* **Formato:** `.gct` (Gene Cluster Text), est√°ndar en bioinform√°tica.
* **Clases biol√≥gicas:**

  * **ALL** ‚Äî *Leucemia Linfobl√°stica Aguda* (48 muestras)
  * **AML** ‚Äî *Leucemia Mieloide Aguda* (25 muestras)

> En total, 73 pacientes y m√°s de 7000 variables por muestra.

---

## üß© Algoritmo: ISOMAP (Tenenbaum et al., 2000)

El **ISOMAP (Isometric Mapping)** combina tres conceptos:

1. **Vecindad local (KNN o Œµ):**
   Conecta cada punto con sus vecinos m√°s pr√≥ximos para formar un grafo.
2. **Distancias geod√©sicas:**
   Calcula la distancia m√≠nima sobre el grafo (no la euclidiana directa).
3. **MDS (Multidimensional Scaling):**
   Proyecta los puntos a un espacio de baja dimensi√≥n preservando las distancias geod√©sicas.

> A diferencia del PCA (que asume linealidad), ISOMAP conserva **estructuras no lineales** del manifold subyacente.

---

## ‚öôÔ∏è Flujo de procesamiento

1. **Lectura y uni√≥n de archivos `.gct`**
   Se cargan `all_aml_train.gct` y `all_aml_test.gct` y se combinan en un √∫nico `DataFrame`.

2. **Limpieza de datos**
   Se eliminan columnas con valores faltantes (`NaN`) para asegurar coherencia en las m√©tricas de distancia.

3. **Estimaci√≥n de vecindad:**

   * **KNN:** 6 vecinos por muestra.
   * **Œµ (epsilon):** valor adaptativo calculado autom√°ticamente desde las distancias al s√©ptimo vecino.

---

## ‚öôÔ∏è Flujo de procesamiento

4. **Construcci√≥n del grafo de conectividad**

   * Si se usa KNN ‚Üí se conecta cada muestra con sus 6 vecinos m√°s cercanos.
   * Si se usa Œµ ‚Üí se conecta cada muestra con todas las que est√©n dentro del radio Œµ.

5. **C√°lculo de distancias geod√©sicas**
   Con `scipy.sparse.csgraph.shortest_path`, obteniendo la matriz completa de distancias entre pares.

---

## ‚öôÔ∏è Flujo de procesamiento

6. **Embedding en 2D (MDS cl√°sico)**
   A partir de la matriz de distancias, se calculan los **autovectores** de la matriz doblemente centrada `B = -0.5 * J D¬≤ J`.

7. **Visualizaci√≥n**
   Se grafican las dos primeras componentes (mayores autovalores) para obtener el plano bidimensional.

---

## üß™ Ejecuci√≥n y salidas

**Comando:**

```bash
python analyze_isomap.py
```

**Resultados generados:**

* `output/isomap_knn.csv` ‚Äî Embedding con K=6 vecinos
* `output/isomap_eps.csv` ‚Äî Embedding con Œµ-vecindad
* `output/isomap_comparison.png` ‚Äî Comparaci√≥n visual de ambos m√©todos

---

## üìä Resultados visuales

### Comparaci√≥n entre m√©todos

<p align="center">
  <img src="../ISOMAP/output/isomap_comparison.png" alt="Incidentes 2018‚Äì2020" width="80%">
</p>

**Izquierda:** ISOMAP con **K=6 vecinos**
**Derecha:** ISOMAP con **Œµ = 107557.388**

---

### üîµ Gr√°fica izquierda ‚Äî *K = 6 vecinos*

* **Representaci√≥n:** Grafo de conectividad con los 6 vecinos m√°s pr√≥ximos.
* **Observaci√≥n:**

  * Clara separaci√≥n entre los grupos **ALL (azul)** y **AML (rojo)**.
  * Los puntos de cada clase se agrupan de forma coherente.
* **Interpretaci√≥n:**

  * El eje X captura la **mayor varianza gen√©tica** entre tipos celulares.
  * El eje Y representa **variaciones secundarias** dentro de cada grupo.
  * Alta cohesi√≥n: las relaciones locales se preservan correctamente.

---

### üî¥ Gr√°fica derecha ‚Äî *Œµ = 107557.388*

* **Representaci√≥n:** Grafo de conectividad por radio (Œµ).
* **Observaci√≥n:**

  * Conexiones excesivas ‚Üí los grupos se mezclan parcialmente.
  * P√©rdida de cohesi√≥n y menor separaci√≥n de clases.
* **Interpretaci√≥n:**

  * El valor de Œµ fue demasiado grande, conectando puntos distantes.
  * Esto degrada la estructura geod√©sica y reduce la interpretabilidad del espacio.

---

## üìà Comparaci√≥n t√©cnica

| Aspecto                   | ISOMAP (K=6 vecinos) ‚úÖ | ISOMAP (Œµ=107557.388) ‚ö†Ô∏è   |
| ------------------------- | ---------------------- | -------------------------- |
| Separaci√≥n ALL vs AML     | Clara                  | Parcial / dispersa         |
| Cohesi√≥n dentro de clases | Alta                   | Baja / irregular           |
| Conectividad del grafo    | Local y robusta        | Global pero ruidosa        |
| Preservaci√≥n geod√©sica    | Buena                  | Afectada por sobreconexi√≥n |
| Interpretabilidad         | Alta                   | Media                      |

---

## üß† Conclusiones finales

* El m√©todo **KNN con K=6** produce un **embedding m√°s interpretable y estable**.
* El m√©todo basado en Œµ requiere una calibraci√≥n m√°s precisa:
  un valor muy grande conecta muestras dis√≠miles, y uno muy peque√±o puede fragmentar el grafo.
* En contextos de datos biom√©dicos de alta dimensi√≥n:

  * ISOMAP **ayuda a identificar patrones gen√©ticos latentes**.
  * Es √∫til para **diagn√≥stico asistido** o exploraci√≥n de subtipos de pacientes.
  * Puede integrarse con **PCA o t-SNE** como t√©cnicas complementarias.